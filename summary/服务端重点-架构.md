# 服务端重点-架构

## 端到端

### 架构设计与业务场景
[link](https://www.cnblogs.com/crazymakercircle/p/14367907.html) 
[link](https://www.cnblogs.com/wpgraceii/p/10528183.html)

#### 系统设计

###### 秒杀

难点：并发量大，应用、数据库都承受不了。难控制超卖。

设计要点：

- 将请求尽量拦截在系统上游，html尽量静态化，部署到cdn上面。按钮及时设置为不可用，禁止用户重复提交请求。
- 设置页面缓存，针对同一个页面和uid一段时间内返回缓存页面。
- 数据用缓存抗，不直接落到数据库。
- 读数据的时候不做强一致性校验，写数据的时候再做。
- 在每台物理机上也缓存商品信息等等变动不大的相关的数据
- 像商品中的标题和描述这些本身不变的会在秒杀开始之前全量推送到秒杀机器上并一直缓存直到秒杀结束。
- 像库存这种动态数据会采用被动失效的方式缓存一定时间（一般是数秒），失效后再去Tair缓存拉取最新的数据。
- 如果允许的话，用异步的模式，等缓存都落库之后再返回结果。
- 如果允许的话，增加答题校验等验证措施。

其他业务和技术保障措施：

- 业务隔离。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就是已知热点，当真正开始时我们可以提前做好预热。
- 系统隔离。系统隔离更多是运行时的隔离，可以通过分组部署的方式和另外 99% 分开。秒杀还申请了单独的域名，目的也是让请求落到不同的集群中。
- 数据隔离。秒杀所调用的数据大部分都是热数据，比如会启用单独 cache 集群或 MySQL 数据库来放热点数据，目前也是不想0.01%的数据影响另外99.99%。

另外需要复习缓存穿透、雪崩等等问题，主要的流量都落在了缓存数据库上，需要针对缓存数据库的高可用作保障。

###### 短链接（分布式ID生成，转字符串，存储）

比较公认的方案：

分布式ID生成器产生ID
ID转62进制字符串
记录数据库，根据业务要求确定过期时间，可以保留部分永久链接
主要难点在于分布式ID生成。鉴于短链一般没有严格递增的需求，可以使用预先分发一个号段，然后生成的方式。

看了下新浪微博的短链接，8位，理论上可以保存超过200万亿对关系，具体怎么存储的还有待研究。

###### 高并发红包系统（类似秒杀，数据库，减库存抢锁，冷热数据分离、请求排队）

红包系统其实很像秒杀系统，只不过同一个秒杀的总量不大，但是全局的并发量非常大，比如春晚可能几百万人同时抢红包。

主要技术难点也类似，主要在数据库，减库存的时候会抢锁。另外由于业务需求不同，没办法异步，也不能超卖，事务更加严格。

不能采用的方式：

乐观锁：手慢会失败，DB 面临更大压力，所以不能采用。
直接用缓存顶，涉及到钱，一旦缓存挂掉就完了。

建议的方式：

接入层垂直切分，根据红包ID，发红包、抢红包、拆红包、查详情等等都在同一台机器上处理，互不影响，分而治之。
请求进行排队，到数据库的时候是串行的，就不涉及抢锁的问题了。
为了防止队列太长过载导致队列被降级，直接打到数据库上，所以数据库前面再加上一个缓存，用CAS自增控制并发，太高的并发直接返回失败。
红包冷热数据分离，按时间分表。

- 分布式id生成器（雪花，时间戳不能回拨）

关键在于是否需要严格递增，严格递增的话效率必然大降。

不需要递增的话比较简单:

一种方式是预先分片，比如十台机器，每台先分一千个ID，一号机从0开始，二号从1000开始等等。缺点是大致上可以被人看出来业务量。

另一种方式是类似雪花算法，每个机器有个id，然后基于时间算一个id，再加上一个递增id。比如如下美团的方案。缺点是机器的时间戳不能回拨，回拨的话会出现问题。

![image](https://img-blog.csdnimg.cn/img_convert/8e2bd38320074336d4bc6aba7a7cf5d5.png)

如果要求严格递增，我没找到现成的很好的方案，大概只能单机生成，不能分布式了，然后都去单机上取号。效率的话，类似Redis的数据库大概能到每秒十几二十几万的速度。
###### 分布式限流器（滑动窗口计数器、令牌桶，redis+lua实现令牌桶）

常见的限流方法：

- 固定窗口计数器：按照时间段划分窗口，有一次请求就+1，最为简单的算法，但这个算法有时会让通过请求量允许为限制的两倍。
- 滑动窗口计数器：通过将窗口再细分，并且按照时间“滑动”来解决突破限制的问题，但是时间区间的精度越高，算法所需的空间容量就越大。
- 漏桶：请求类似水滴，先放到桶里，服务的提供方则按照固定的速率从桶里面取出请求并执行。缺陷也很明显，当短时间内有大量的突发请求时，即便此时服务器没有任何负载，每个请求也都得在队列中等待一段时间才能被响应。
- 令牌桶：往桶里面发放令牌，每个请求过来之后拿走一个令牌，然后只处理有令牌的请求。令牌桶满了则多余的令牌会直接丢弃。令牌桶算法既能够将所有的请求平均分布到时间区间内，又能接受服务器能够承受范围内的突发请求，因此是目前使用较为广泛的一种限流算法。

Google 的开源项目 guava 提供了 RateLimiter 类，实现了单点的令牌桶限流。

分布式环境下，可以考虑用 Redis+Lua 脚本实现令牌桶。

如果请求量太大了，Redis 也撑不住怎么办？我觉得可以类似于分布式 ID 的处理方式，Redis 前面在增加预处理，比如每台及其预先申请一部分令牌，只有令牌用完之后才去 Redis。如果还是太大，是否可以垂直切分？按照流量的来源，比如地理位置、IP 之类的再拆开。

###### 分布式定时任务（任务轮询+排队抢占）

任务轮询或任务轮询+抢占排队方案

- 每个服务器首次启动时加入队列；
- 每次任务运行首先判断自己是否是当前可运行任务，如果是便运行；
- 如果不是当前运行的任务，检查自己是否在队列中，如果在，便退出，如果不在队列中，进入队列。

###### 新浪微博推送机制（关系复杂、数据量大，推给在线粉丝，上线拉，冷热数据分离）

主要难点：关系复杂，数据量大。一个人可以关注非常多的用户，一个大 V 也有可能有几千万的粉丝。

先介绍最基本的方案：

- 推模式：推模式就是，用户A关注了用户 B，用户 B 每发送一个动态，后台遍历用户B的粉丝，往他们粉丝的 feed 里面推送一条动态。
- 拉模式：推模式相反，拉模式则是，用户每次刷新 feed 第一页，都去遍历关注的人，把最新的动态拉取回来。

一般采用推拉结合的方式，用户发送状态之后，先推送给粉丝里面在线的用户，然后不在线的那部分等到上线的时候再来拉取。

另外冷热数据分离，用户关系在缓存里面可以设置一个过期时间，比如七天。七天没上线的可能就很少用这个 APP。

###### 大文件有序内存排序（远高于内存，分隔，分别排序，缓冲区）

对于远高于内存的文件排序。

外归并排序：

- 对文件分割，然后分别排序。
- 排好序的文件依次读取一个缓冲区的大小，然后进行排序，输出到输出缓冲区，然后保存到结果文件。

如果是数字，可以用位图排序，但是要求比较苛刻：
- 数字不重复
- 知道最大值
- 相对密集，因为没出现的数字也会占用空间
- 
比较适合电话号之类的。

#### 子业务场景

###### 外卖送单，保证只有一人接到（redis的lpush、rpop）
###### 加权推荐商家置顶，第二天更新（堆排序，第二天更新前redis准备好数据同步到db）
###### 微信抢红包（悲观锁、乐观锁、存储过程在mysql中）
###### 多任务分配有限人处理及优化（对象池、任务入N个队列，人去对应的队列取任务）
###### 保证发送消息的有序性（消息加header、识别header的syn）
###### 文件快速下发到服务（边下发边复制）
###### 多态机器存储大量日志，一台电脑选出热度最高的是个关键词（分bucket、分治法与多路归并）
###### 分布式集群如何保证线程安全（分布式锁，让分布式多线程对一个共享资源一次性只能有一个线程获取到锁里的资源，redis、zk居多）

#### 实现方式与概念

###### 负载均衡原理是什么?
###### 滑动窗口的概念以及应用（流量控制技术，改善吞吐量，用在数据链路层、传输层）
###### 怎么做弹性扩缩容，原理是什么
###### 说一下中间件原理，设计
###### 设计一个web框架，你要怎么设计，说一下步骤
###### 怎么搞一个并发服务程序
###### 怎么做一个自动化配置平台系统
###### 各个系统出问题怎么监控报警
###### 怎么设计orm，让你写,你会怎么写

#### 思路

从以下几个方面准备：
- 先了解常用算法，针对解决各种问题能用哪些算法，比如大文件排序用外排序，大量数据中的命中判断用位图/布隆过滤器等等。
- 注意扩展性、多考虑极端情况，多问自己几个为什么。比如说起单机的限流算法想想分布式的怎么做。
- 实在不知道怎么弄的叙述自己的思考过程，着重展示自己考虑周全、思维缜密。
