# 服务端重点-架构

## 业务场景与端到端架构设计

[link](https://www.cnblogs.com/crazymakercircle/p/14367907.html)
[link](https://www.cnblogs.com/wpgraceii/p/10528183.html)

### 秒杀

难点：并发量大，应用、数据库都承受不了。难控制超卖。

![秒杀验证逻辑](https://github.com/cbirdcn/note/assets/60061199/12e56962-d18d-4cb6-973a-0a2aee5833e2)

设计要点：

- 静态化：将请求尽量拦截在系统上游，html尽量静态化，部署到cdn上面。按钮及时设置为不可用，禁止用户重复提交请求。非覆盖式发布，静态资源必须共存多个静态版本。在 CDN 服务商提供的空间中，将回源地址配置为源站，而不是在代码中填写源站信息。
- 防止重复请求：设置页面缓存，针对同一个页面和uid一段时间内返回缓存页面。
- 访问缓存：数据用缓存抗，不直接落到数据库。
- 非强一致：读数据的时候不做强一致性校验，写数据的时候再做。
- 主机缓存：在每台物理机上也缓存商品详情、交易系统数据等等变动不大的相关的数据，避免网络交互耗时。
- 预加载缓存：像商品中的标题和描述这些本身不变的会在秒杀开始之前全量推送到秒杀机器上并一直缓存直到秒杀结束。
- 缓存随机失效：像库存这种动态数据会采用被动失效的方式缓存一定时间（一般是数秒），失效后再去Tair缓存拉取最新的数据。
- 异步防缓存穿透：如果允许的话，用异步的模式，等缓存都落库之后再返回结果。
- 流量削峰：请求排队、增加答题校验、逐层过滤无效请求、写操作限流抛弃系统承载能力外的请求等验证措施。

其他业务和技术保障措施：

- 业务隔离，预知规模。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就是已知热点，当真正开始时我们可以提前做好预热。
- 系统隔离，防雪崩。系统隔离更多是运行时的隔离，可以通过分组部署的方式和另外 99% 分开。秒杀还申请了单独的域名，目的也是让请求落到不同的集群中。从经济方面考虑，实在不能分开的系统就通过对服务器调用进行哈希分组，将热点请求分配到同一分组，防止对其他业务造成影响。
- 数据隔离，冷热分离。秒杀所调用的数据大部分都是热数据，比如会启用单独 cache 集群或 MySQL 数据库来放热点数据，目前也是不想0.01%的数据影响另外99.99%。

另外需要复习缓存穿透、雪崩等等问题，主要的流量都落在了缓存数据库上，需要针对缓存数据库的高可用作保障。

[如何设计一个秒杀系统08-答疑解惑：缓存失效的策略应该怎么定？](https://blog.csdn.net/sucaiwa/article/details/130758671)

[如何设计一个秒杀系统04-流量削峰这事应该怎么做？](https://blog.csdn.net/sucaiwa/article/details/130740127)

[系列文章](https://blog.csdn.net/sucaiwa/category_12312921.html)

### 短链接（分布式ID生成，转字符串，存储）

比较公认的方案：

- 分布式ID生成器产生ID
- ID转62进制字符串
- 记录数据库，根据业务要求确定过期时间，可以保留部分永久链接
- 主要难点在于分布式ID生成。鉴于短链一般没有严格递增的需求，需要用雪花算法。否则如果按照机器数量预先分发一个号段，很难处理动态增减机器，以及容易被看出业务规模。

看了下新浪微博的短链接，8位，理论上可以保存超过200万亿对关系，具体怎么存储的还有待研究。

[分布式ID生成器之雪花算法简介](https://zhuanlan.zhihu.com/p/85837641)

[Leaf——美团点评分布式ID生成系统](https://tech.meituan.com/2017/04/21/mt-leaf.html)

![image](https://img-blog.csdnimg.cn/img_convert/8e2bd38320074336d4bc6aba7a7cf5d5.png)

雪花算法分布式ID组成部分（64bit）
- 第一位 占用1bit，其值始终是0，没有实际作用。 
- 时间戳 占用41bit，精确到毫秒，总共可以容纳约69年的时间。 
- 工作机器id 占用10bit，其中高位5bit是数据中心ID，低位5bit是工作节点ID，做多可以容纳1024个节点。 
- 序列号 占用12bit，每个节点每毫秒0开始不断累加，最多可以累加到4095，一共可以产生4096个ID。

SnowFlake算法在同一毫秒内最多可以生成多少个全局唯一ID呢：： 同一毫秒的ID数量 = 1024 X 4096 = 4194304

优点是不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，是递增且唯一的。缺点是，如果服务器出现时钟回拨，可以导致ID重复。

时间位可以是与某个指定时间点的时间戳差值，而不是时间戳的0值.

MongoDB的ObjectID也是通过"时间+机器码+pid+inc"共12个字节，通过4+3+2+3的方式最终标识成一个24长度的十六进制字符。

对于worker_id的确定，可以借助通过 Zookeeper、Consul、Etcd 等提供分布式配置功能的中间件，也可以直接通过该机器的ip或本机配置获取worker id。

由于强依赖时钟，对时间的要求比较敏感，在机器工作时NTP同步也会造成秒级别的回退，建议可以直接关闭NTP同步。要么在时钟回拨的时候直接不提供服务直接返回ERROR_CODE，等时钟追上即可。或者做一层重试，然后上报报警系统，更或者是发现有时钟回拨之后自动摘除本身节点并报警。

实现关键代码

```Java
public class SnowFlakeService {
    //起始时间戳( 2020-12-26 00:00:00 )
    private static final long START_STAMP = 1608912000000L;

    //序列号最大值
    private static final long MAX_SEQUENCE = -1L ^ (-1L << 12); // 4095

    private static long sequence; //序列号  range(0 ~ 4095)

    public static synchronized long getNextId() {
        long currentStamp = System.currentTimeMillis();

        if (currentStamp < lastStamp) {
            throw new IllegalArgumentException("时间被回退，不能继续产生id");
        }

        if (currentStamp == lastStamp) {
            //相同毫秒内，序列号自增
            sequence = (sequence + 1) & MAX_SEQUENCE;
            if (sequence == 0L) {
                //序列号已经到最大值
                System.out.println("序列号已经到达最大值");
                //使用下一个时间戳(如果还没到下一时间戳，就陷入阻塞直至获得下一个时间戳才返回)
                currentStamp = getNextStamp();
            }
        } else {
            //不同毫秒，序列号重置
            sequence = 0L;
        }

        lastStamp = currentStamp;//当前时间戳存档，用于判断下次产生id时间戳是否相同

        return (currentStamp - START_STAMP) << TIMESTAMP_LEFT
                | dataCenterId << DATACENTER_LEFT
                | machineId << MACHINE_LEFT
                | sequence;
    }

    /**
     * 阻塞直至获得下一个时间戳
     * 注意：本机获取时间效率不够高，并且可能因为NTP导致时钟回拨出现错误。美团 Leaf-snowflake 方案引入zookeeper，每隔一段时间让本机上报时间，首先从zookeeper服务获取时间，如果发生回拨就拒绝服务或等待时钟恢复到递增，如果zookeeper服务异常才从本机获取时间。
     *
     * @return
     */
    public static long getNextStamp() {

        long newStamp = getCurrentStamp();
        while (newStamp <= lastStamp) {
            newStamp = getCurrentStamp();
        }

        return newStamp;
    }

    ...
}
```

### 高并发红包系统（类似秒杀，数据库，减库存抢锁，冷热数据分离、请求排队）

微信红包（尤其是发在微信群里的红包，即群红包），业务形态上很类似网上的普通商品秒杀活动。

就像下面这样：
- 用户在微信群里发一个红包，等同于是普通商品秒杀活动的商品上架；
- 微信群里的所有用户抢红包的动作，等同于秒杀活动中的查询库存，减库存的时候会抢锁；
- 用户抢到红包后拆红包的动作，则对应秒杀活动中用户的秒杀动作。

不过除了上面的相同点之外，微信红包在业务形态上与普通商品秒杀活动相比，还具备自身的特点。

首先：**微信红包业务比普通商品秒杀有更海量的并发要求**。

微信红包用户在微信群里发一个红包，等同于在网上发布一次商品秒杀活动。假设同一时间有 10 万个群里的用户同时在发红包，那就相当于同一时间有 10 万个秒杀活动发布出去。10 万个微信群里的用户同时抢红包，将产生海量的并发请求。也就是说，同一个秒杀的总量不大，但是全局的并发量非常大，比如春晚可能几百万人同时抢红包。

其次：**微信红包业务要求更严格的安全级别**。

微信红包业务本质上是资金交易。微信红包是微信支付的一个商户，提供资金流转服务。

用户发红包时，相当于在微信红包这个商户上使用微信支付购买一笔钱，并且收货地址是微信群。当用户支付成功后，红包发货到微信群里，群里的用户拆开红包后，微信红包提供了将钱转入折红包用户微信零钱的服务。

资金交易业务比普通商品秒杀活动有更高的安全级别要求。普通的商品秒杀商品由商户提供，库存是商户预设的，秒杀时可以允许存在超卖（即实际被抢的商品数量比计划的库存多）、少卖（即实际被抢的商户数量比计划的库存少）的情况。但是对于微信红包，用户发 100 元的红包绝对不可以被拆出 101 元；用户发 100 元只被领取 99 元时，剩下的 1 元在 24 小时过期后要精确地退还给发红包用户，不能多也不能少。

以上是微信红包业务模型上的两大特点。

不能采用的方式：

- 乐观锁：DB 面临更大压力，以及事务回滚，所以不能采用。
- 直接用缓存顶，涉及到钱，一旦缓存挂掉就完了。

建议的方式：

- 接入层垂直切分，根据红包ID，发红包、抢红包、拆红包、查详情等等都在同一台机器上处理，互不影响，分而治之。
- 请求进行排队，到数据库的时候是串行的，就不涉及抢锁的问题了。
- 为了防止队列太长过载导致队列被降级，直接打到数据库上，所以数据库前面再加上一个缓存，用CAS自增控制并发，太高的并发直接返回失败。
- 红包冷热数据分离，按时间分表。
- 分布式id生成器（雪花，时间戳不能回拨）。

对 DB 的操作流程有以下三步，这三步操作需要在一个事务中完成：
- 锁库存；避免并发请求时出现超卖情况
- 插入秒杀记录；
- 更新库存。

设计难点就在这个事务操作上。商品库存在 DB 中记为一行，大量用户同时秒杀同一商品时，第一个到达 DB 的请求锁住了这行库存记录。在第一个事务完成提交之前这个锁一直被第一个请求占用，后面的所有请求需要排队等待。同时参与秒杀的用户越多，并发进 DB 的请求越多，请求排队越严重。因此，**并发请求抢锁，是典型的商品秒杀系统的设计难点**。

[社交软件红包技术解密(四) 微信红包系统是如何应对高并发的](http://www.52im.net/thread-2548-1-1.html)

[社交软件红包技术解密(一)：全面解密QQ红包技术方案——架构、技术实现等](http://www.52im.net/thread-2202-1-1.html)

在接入层，为了解决同时存在海量事务级操作的问题，将海量化为小量。可以
- 微信红包用户发一个红包时，微信红包系统生成一个 ID 作为这个红包的唯一标识。接下来这个红包的所有发红包、抢红包、拆红包、查询红包详情等操作，都根据这个 ID 关联。
- 红包系统根据这个红包 ID，按一定的规则哈希（如按 ID 尾号取模等），垂直上下切分。比如采用了一致性 Hash 寻址，保证同一个用户的请求只会落在同一台红包抽奖逻辑机器处理。切分后，一个垂直链条上的逻辑 Server 服务器、DB 统称为一个 SET。
- 各个 SET 之间相互独立，互相解耦。并且同一个红包 ID 的所有请求，包括发红包、抢红包、拆红包、查详情详情等，垂直 stick 到同一个 SET 内处理，高度内聚。通过这样的方式，系统将所有红包请求这个巨大的洪流分散为多股小流，互不影响，分而治之

在抽奖阶段，进行按设计合理的几率完成抽奖操作，将抽奖结果安全落地保存，并顺利发货等过程。面对海量抽奖请求，如何及时作出响应，是抽奖系统面临的难题。需要
- 在接入层采用一致性 Hash 算法：同一用户的抽奖请求只会转发到相同的抽奖系统处理;
- 抽奖系统采用缓存机制：在加快抽奖过程的同时也减少了对存储层的访问压力；
- 奖品配额机制：平滑抽奖过程，各类奖品按比例有序抽中；
- 流水和对账机制：保证抽奖数据最终无差错发放到用户账户中。

抽奖之前，需要先进行安全审计、账号鉴权、用户信息查询，然后执行抽奖逻辑后写入流水系统。流水系统和发货系统通过异步对账，保证库存变化和不会超卖。当抽奖模块请求发货系统给用户发货时，发货系统将执行发放过程。

另外，为了尽可能在抽奖前阶段缓存更多数据，而避免动态查询，可以将用户信息缓存在主机内存中，如果要从业务测改变中奖逻辑，还可以缓存用户中奖历史信息。

流水系统用于保存活动过程中的抽奖流水记录，可以在活动后对奖品发放和领用进行统计和对账。该系统还定时对领用失败的请求进行重做和对账，确保奖品发放到用户账户里。由于流水需要记录用户中奖的信息和领用的的情况，数据量巨大，所以抽奖逻辑层本地采用顺序写文件的方式进行记录。抽奖逻辑层会定期的把本地的流水文件同步到远程流水系统进行汇总和备份，同时，流水系统会对领用失败的流水进行重做，发送请求到抽奖逻辑层，抽奖逻辑层会调用发货系统的接口完成发货操作。

发货系统可能会对接各种不同的业务接口，为了避免发奖请求引起业务侧雪崩，就需要发货系统有队列延迟功能，可以暂存发奖信息，延迟发货。可以采用开源的 RocketMQ 消息中间件作为异步消息队列，暂存发货请求，再由礼券发货模块根据各业务的限速配置均匀地调用业务接口进行发货。

发货模块首先会到存储系统检查奖品是否真实有效，再到发货状态存储检查状态是否正常，只有真正需要的发货的奖品才向业务系统发起发货请求，确保发货的有效性，避免错发和多发。

由于采用异步发货，抽奖时刻奖品不能保证立即发放到用户账户中。但用户的奖品不会丢失，通过在异步队列中暂存，礼券发货模块逐步以合适的速度将奖品发放到用户账户中。如果发货过程中有延时或失败，用户可以通过多次领取提起发货请求，系统支持多次提交。如果多次发货仍然失败，对账工具第 2 天会从流水系统中将用户抽奖数据与发货数据进行对账，对发货异常用户再次发起发货。如果对账仍然失败，则提醒管理人员介入处理。

另外，在客户端也需要做一些工作
- 资源预加载。不经常变化的静态资源，如页面，图片，JS 等，会分发到各地 CDN 以提高访问速度，只有动态变化的内容，才实时从后台拉取。然而即使所有的静态资源都采用了 CDN 分发，如果按实际流量评估，CDN 的压力仍然无法绝对削峰。因为同时访问红包页面的人数比较多，按 83 万 / 秒的峰值，一个页面按 200K 评估，约需要 158.3G 的 CDN 带宽，会给 CDN 带来瞬间很大的压力。为减轻 CDN 压力，QQ 红包使用了手机 QQ 离线包机制提前把红包相关静态资源预加载到手机QQ移动端，这样可大大降低 CDN 压力。可以让将静态资源放入预加载列表，用户登录时分批次加载。也可以主动推送离线包，适合紧急更新，比如节日红包。
- 定时请求服务器避免频繁刷新。2.59 亿用户同时在线，用户刷一刷时的峰值高达 83 万 / 秒，用户每次刷的操作都向后台发起请求是没有必要的，因此手机 QQ 在移动端对用户刷一刷的操作进行计数，定时（1~3 秒）异步将汇总数据提交到后台抽奖，再将抽奖结果回传到手机 QQ 移动端显示。这样既保证了刷的畅快体验，也大大减轻后台压力，抽奖结果也在不经意间生产，用户体验完全无损。
- 错峰。对用户进行分组，不同组的用户刷一刷红包（企业明星红包、AR 红包等）的开始时间并不相同，而是错开一段时间（1~5 分钟）

### 分布式限流器（滑动窗口计数器、令牌桶，redis+lua实现令牌桶）

当遇到瞬时请求量激增或恶意请求时，会导致接口占用过多服务器资源，使得其他请求响应速度降低或是超时，更有甚者可能导致服务器宕机。

限流(Ratelimiting)指对应用服务的请求进行限制，例如某一接口的请求限制为 100 个每秒,对超过限制的请求则进行快速失败或丢弃。

[分布式服务限流实战](https://www.infoq.cn/article/qg2tx8fyw5vt-f3hh673)

常见的限流方法：

- 固定窗口计数器：按照时间段划分窗口，有一次请求就+1，最为简单的算法，但这个算法有时会让通过请求量允许为限制的两倍。
- 滑动窗口计数器：通过将窗口再细分，并且按照时间滑动来解决突破限制的问题，但是时间区间的精度越高，算法所需的空间容量就越大。
- 漏桶：请求类似水滴，先放到桶里，服务的提供方则按照固定的速率从桶里面取出请求并执行。缺陷也很明显，当短时间内有大量的突发请求时，即便此时服务器没有任何负载，每个请求也都得在队列中等待一段时间才能被响应。
- 令牌桶：往桶里面发放令牌，每个请求过来之后拿走一个令牌，然后只处理有令牌的请求。令牌桶满了则多余的令牌会直接丢弃。令牌桶算法既能够将所有的请求平均分布到时间区间内，又能接受服务器能够承受范围内的突发请求，因此是目前使用较为广泛的一种限流算法。

![令牌桶限流算法](https://static001.infoq.cn/resource/image/ec/93/eca0e5eaa35dac938c673fecf2ec9a93.png)

Google 的开源项目 guava 提供了 RateLimiter 类，实现了单点的令牌桶限流。

分布式环境下，常用的有 Hystrix、resilience4j、Sentinel 等框架，但这些框架都需引入第三方的类库。

[Sentinel: The Sentinel of Your Microservices](https://github.com/alibaba/Sentinel)

也可以考虑用 Redis的hash+Lua 脚本实现令牌桶。

- 为实现限流算法，需要反复调用 Redis 查询与计算，一次限流判断需要多次请求较为耗时。因此我们采用编写 Lua 脚本运行的方式，将运算过程放在 Redis 端，使得对 Redis 进行一次请求就能完成限流的判断。
- 令牌桶算法需要在 Redis 中存储桶的大小、当前令牌数量，并且实现每隔一段时间添加新的令牌。最简单的办法当然是每隔一段时间请求一次 Redis，将存储的令牌数量递增。但实际上我们可以通过对限流两次请求之间的时间和令牌添加速度来计算得出上次请求之后到本次请求时，令牌桶应添加的令牌数量。因此我们在 Redis 中只需要存储上次请求的时间和令牌桶中的令牌数量，而桶的大小和令牌的添加速度可以通过参数传入实现动态修改。
- 由于第一次运行脚本时默认令牌桶是满的，因此可以将数据的过期时间设置为令牌桶恢复到满所需的时间，及时释放资源。
- 如果请求量太大了，Redis 也撑不住怎么办？请注意，在分布式下实现限流，需要把你的计数器和漏桶队列维护到一个公共的地方，比如redis，zookeeper，数据库等。

或者用队列实现

[自己动手写令牌桶、漏桶、计数等限流实现](https://cloud.tencent.com/developer/article/1165247)

### 分布式定时任务（任务轮询+排队抢占）

[分布式定时任务框架选型](https://cloud.tencent.com/developer/article/1962298)

几个业务场景:
- 支付系统每天凌晨1点跑批，进行一天清算，每月1号进行上个月清算
- 电商整点抢购，商品价格8点整开始优惠
- 12306购票系统，超过30分钟没有成功支付订单的，进行回收处理
- 商品成功发货后，需要向客户发送短信提醒

一般来说，系统可以使用消息传递代替部分定时任务，两者有很多相似之处，可以相互替换场景。如，上面发货成功发短信通知客户的业务场景，我们可以在发货成功后发送MQ消息到队列，然后去消费mq消息，发送短信。

但在某些场景下不能互换：
- 时间驱动/事件驱动：内部系统一般可以通过时间来驱动，但涉及到外部系统，则只能使用时间驱动。如怕取外部网站价格，每小时爬一次
- 批量处理/逐条处理：批量处理堆积的数据更加高效，在不需要实时性的情况下比消息中间件更有优势。而且有的业务逻辑只能批量处理。如移动每个月结算我们的话费
- 实时性/非实时性：消息中间件能够做到实时处理数据，但是有些情况下并不需要实时，比如：vip升级
- 系统内部/系统解耦：定时任务调度一般是在系统内部，而消息中间件可用于两个系统间

分布式定时任务框架
- elastic-job：当当开发的弹性分布式任务调度系统，功能丰富强大，采用zookeeper实现分布式协调，实现任务高可用以及分片，并且可以支持云开发。
- xxl-job：是大众点评员工徐雪里于2015年发布的分布式任务调度平台，是一个轻量级分布式任务调度框架，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。

发货后超过10天未收货时系统自动确认收货的多种实现方式：

每天定时半夜筛选第二天 可以自动确认收货的订单,然后第二天 每10分钟 执行一次确认收货 开销不会太大吧 时间也相对精确
自动确认收货这个状态如果仅仅是让客户端看的话，等用户下一次上线的时间，做一次运算就可以了。
延迟和定时消息投递
ActiveMQ提供了一种broker端消息定时调度机制。适用于：1、不希望消息马上被broker投递出去，而是想要消息60秒以后发给消费者，2、想让消息每隔一定时间投递一次，一共投递指定的次数
RabbitMQ可以针对Queue和Message设置 x-message-tt，来控制消息的生存时间，如果超时，则消息变为dead letter。利用DLX，当消息在一个队列中变成死信后，它能被重新publish到另一个Exchange。这时候消息就可以重新被消费。

自己实现的话，要根据任务轮询或任务轮询+抢占排队方案

- 每个服务器首次启动时加入队列；
- 每次任务运行首先判断自己是否是当前可运行任务，如果是便运行；
- 如果不是当前运行的任务，检查自己是否在队列中，如果在，便退出，如果不在队列中，进入队列。

### 新浪微博缓存架构和推送机制（关系复杂、数据量大，推给在线粉丝，上线拉，冷热数据分离）

[日访问量百亿级的微博如何做缓存架构设计](https://www.infoq.cn/article/5kr7jo6jssu15db8h7ay)

在主站或客户端点一下刷新，最新获得了十到十五条微博，它这个是怎么构建出来的呢？刷新之后，首先会获得用户的关注关系，比如她有一千个关注，会把这一千个 ID 拿到，根据这一千个 UID，拿到每个用户发表的一些微博，同时会获取这个用户的 Inbox，就是她收到的特殊的一些消息，比如分组的一些微博，群的微博，下面她的关注关系，她关注人的微博列表，拿到这一系列微博列表之后进行集合、排序，拿到所需要的那些 ID，再对这些 ID 去取每一条微博 ID 对应的微博内容，如果这些微博是转发过来的，它还有一个原微博，会进一步取原微博内容，通过原微博取用户信息，进一步根据用户的过滤词，对这些微博进行过滤，过滤掉用户不想看到的微博，留下这些微博后，再进一步来看，用户对这些微博有没有收藏、赞，做一些 flag 设置，最后还会对这些微博各种计数，转发、评论、赞数进行组装，最后才把这十几条微博返回给用户的各种端。这样看，用户一次请求，最终得到十几条记录，后端服务器大概要对几百甚至几千条数据进行实时组装，再返回给用户，整个过程对 Cache 体系强度依赖。所以 Cache 架构设计优劣直接会影响到微博体系表现的好坏。

微博 Cache 架构演进过程，最开始微博上线的时候，都是把它作为一个简单的 KV 证人数据类型来存储，我们主要采取哈希分片存储在 MC 池子里，上线几个月之后发现一些问题，有一些节点机器宕机或者其它方面原因，大量的请求会穿透 Cache 层达到 DB 上去，导致整个请求变慢，甚至 DB 僵死。于是我们很快给它改造增加一个 HA 层，这样即便 Main 层出现某些节点宕机情况或者挂掉之后，这些请求会进一步穿透到 HA 层，不会穿透 DB 层，这样的话可以保证在任何情况下，整个系统命中率不会降低，系统服务稳定性比较大提升。

微博和微信很大的区别，实际上微博是一个广场型的业务，比如突发事件，某明星找个女朋友，瞬间流量就 30%，突发事件后，大量的请求会出现在某一些节点，会导致这个节点非常热，即便是 MC 也没办法满足这么大的请求量。这时候整个 MC 就会变成瓶颈，导致整个系统变慢，基于这个原因我们引入 L1 层，还是一个 Main 关系池，每一个 L1 大概是 Main 层的 N 分之一，六分之一、八分之一、十分之一这样一个内存量，根据请求量我会增加 4 到 8 个 L1，这样所有的请求来了之后首先会访问 L1，L1 命中的话就会直接访，如果没有命中再来访问 Main-HA 层，这样在一些突发流量的时候，可以由 L1 来抗住大部分热的请求。对微博本身来说，新的数据就会越热，只用增加很少一部分内存就会抗住更大的量。

对读写策略，采取多写，读的话采用逐层穿透，如果 Miss 的话就进行回写，对存在里面的数据，我们最初采用 Json/xml，12 年之后就直接采用 Protocol| Buffer 格式，对一些比较大的用 QuickL 进行压缩。

对于复杂的集合类数据怎么来处理，比如我关注了 2000 人，新增一个人，这就涉及到部分修改。有一种方式把 2000 个 ID 全部拿下来进行修改，这种对带宽、机器压力会更大。还有一些分页获取，我存了 2000 个，只需要取其中的第几页，比如第二页，也就是第十到第二十个，能不能不要全量把所有数据取回去。还有一些资源的联动计算，会计算到我关注的某些人里面 ABC 也关注了用户 D，这种涉及到部分数据的修改、获取，包括计算，对 MC 来说它实际上是不太擅长的。各种关注关系都存在 Redis 里面取，通过 Hash 分布、储存，一组多存的方式来进行读写分离。现在 Redis 的内存大概有 30 个 T，每天都有 2-3 万亿的请求。

在使用 Redis 的过程中实际上还是遇到其他一些问题，比如从关注关系，我关注了 2000 个 UID，有一种方式是全量存储，但微博有大量的用户，有些用户登陆比较少，有些用户特别活跃，这样全部放在内存里面成本开销是比较大的。所以我们就把 Redis 使用改成 Cache，比如只存活跃的用户，如果你最近一段时间没有活跃之后，会把你从 Redis 里面踢掉，再次有访问到你的时候把你加进来。这时候存在一个问题，Redis 工作机制是单线程模式，如果它加某一个 UV，关注 2000 个用户，可能扩展到两万个 UID，两万个 UID 塞回去基本上 Redis 就卡住了，没办法提供其他服务。所以我们扩展一种新的数据结构，两万个 UID 直接开了端，写的时候直接依次把它写到 Redis 里面去，读写的整个效率就会非常高，它的实现是一个 long 型的开放数组，通过 Double Hash 进行寻址。

对 Redis 来说我们进行了一些其他的扩展，之前的一些分享，大家在网上也会看到，把数据放到公共变量里面，整个升级过程，我们测试 1G 的话加载要 10 分钟，10G 大概要十几分钟以上，现在是毫秒级升级。对于 AOF，我们采用滚动的 AOF，每个 AOF 是带一个 ID 的，达到一定的量再滚动到下一个 AOF 里面去。对 RDB 落地的时候，我们会记录构建这个 RDB 时，AOF 文件以及它所在的位置，通过新的 RDB、AOF 扩展模式，实现全增量复制。

接下来还有一些其他的数据类型，比如一个计数，实际上计数在每个互联网公司都可能会遇到，对一些中小型的业务来说，实际上 MC 和 Redis 足够用的，但在微博里面计数出现了一些特点，单条 Key 有多条计数，比如一条微博，有转发数、评论数、还有点赞，一个用户有粉丝数、关注数等各种各样的数字，因为是计数，它的 Value size 是比较小的，根据它的各种业务场景，大概就是 2-8 个字节，一般 4 个字节为多，然后每日新增的微博大概十亿条记录，总记录就更可观了，然后一次请求，可能几百条计数要返回去。

最初是可以采取 Memcached，但它有个问题，如果计数超过它内容容量的时候，它会导致一些计数的剔除，宕机或重启后计数就没有了。另外可能有很多计数它是为零，那这个时候怎么存，要不要存，存的话就占很多内存。微博每天上十亿的计数，光存 0 都要占大量的内存，如果不存又会导致穿透到 DB 里面去，对服务的可溶性就会存在影响。2010 年之后我们又采用 Redis 访问，随着数据量越来越大之后，发现 Redis 内存有效负荷还是比较低的，它一条 KV 大概需要至少 65 个字节，但实际上我们一个计数需要 8 个字节，然后 Value 大概 4 个字节，实际上有效只有 12 个字节，其他还有四十多个字节都是被浪费掉的，这还只是单个 KV，如果一条 Key 有多个计数的情况下，它就浪费得更多了，比如说四个计数，一个 Key8 个字节，四个计数每个计数是 4 个字节，16 个字节大概需要 26 个字节就行了。但是用 Redis 存大概需要 200 多个字节。后来通过自己研发 Counter Service，内存降至 Redis 的五分之一到十五分之一以下，而且进行冷热分离，热数据存在内存里面，冷数据如果重新变热，就把它放到 LRU 里面去。落地 RDB、AOF，实现全增量复制，通过这种方式，热数据单机可以存百亿级，冷数据可以存千亿级。

在内存里面是预先把它分成 N 个 Table，每个 Table 根据 ID 的指针序列，划出一定范围，任何一个 ID 过来先找到它所在的 Table，如果有直接对它增增减减，有新的计数过来，发现内存不够的时候，就会把一个小的 Table Dump 到 SSD 里面去，留着新的位置放在最上面供新的 ID 来使用。有些人疑问说，如果在某个范围内，我的 ID 本来设的计数是 4 个字节，但是微博特别热，超过了 4 个字节，变成很大的一个计数怎么处理，对于超过限制的把它放在 Aux dict 进行存放，对于落在 SSD 里面的 Table，我们有专门的 IndAux 进行访问，通过 RDB 方式进行复制。

除了计数的话，微博还有一些业务，一些存在性判断，比如一条微博展现的，有没有点赞、阅读、推荐，如果这个用户已经读过这个微博了，就不要再显示给他，这种有个很大的特点，它检查是否存在，每条记录非常小，比如 Value1 个 bit 就可以了，但总数据量巨大。比如微博每天新发表微博 1 亿左右，读的可能有上百亿、上千亿这种总的数据需要判断，怎么来存储是个很大的问题，而且这里面很多存在性就是 0，还是前面说的，0 要不要存，如果存了，每天就存上千亿的记录，如果不存，那大量的请求最终会穿透 Cache 层到 DB 层，任何 DB 都没有办法抗住那么大的流量。

首先直接考虑我们能不能用 Redis，单条 KV65 个字节，一个 KV 可以 8 个字节的话，Value 只有 1 个 bit，这样算下来我每日新增内存有效率是非常低的。第二种我们新开发的 Counter Service，单条 KV Value1 个 bit，我就存 1 个 byt，总共 9 个 byt 就可以了，这样每日新增内存 900G，存的话可能就只能存最新若干天的，存个三天差不多快 3 个 T 了，压力也挺大，但比 Redis 已经好很多。

最终方案采用自己开发 Phantom，先采用把共享内存分段分配，最终使用的内存只用 120G 就可以，算法很简单，对每个 Key 可以进行 N 次哈希，如果哈希的某一个位它是 1，如果进行 3 次哈希，三个数字把它设为 1，把 X2 也进行三次哈希，后面来判断 X1 是否存在的时候，进行三次哈希来看，如果都为 1 就认为它是存在的，如果某一个哈希 X3，它的位算出来是 0，那就百分百肯定不存在的。

它的实现架构比较简单，把共享内存预先拆分到不同 Table 里面，在里面进行开方式计算，然后读写，落地的话采用 AOF+RDB 的方式进行处理。整个过程因为放在共享内存里面，进程要升级重启数据也不会丢失。对外访问的时候，建 Redis 协议，它直接扩展新的协议就可以访问我们这个服务了。

存储成本以及运维性呢？

采取的方案首先就是对整个 Cache 进行服务化管理，对配置进行服务化管理，避免频繁重启，另外如果配置发生变更，直接用一个脚本修改一下。

服务化还引入 Cluster Manager，实现对外部的管理，通过一个界面来进行管理，可以进行服务校验。服务治理方面，可以做到扩容、缩容，SLA 也可以得到很好保障。

主要难点：关系复杂，数据量大。一个人可以关注非常多的用户，一个大 V 也有可能有几千万的粉丝。

先介绍最基本的方案：

- 推模式：推模式就是，用户A关注了用户 B，用户 B 每发送一个动态，后台遍历用户B的粉丝，往他们粉丝的 feed 里面推送一条动态。
- 拉模式：推模式相反，拉模式则是，用户每次刷新 feed 第一页，都去遍历关注的人，把最新的动态拉取回来。

一般采用推拉结合的方式，用户发送状态之后，先推送给粉丝里面在线的用户，然后不在线的那部分等到上线的时候再来拉取。

另外冷热数据分离，用户关系在缓存里面可以设置一个过期时间，比如七天。七天没上线的可能就很少用这个 APP。

### 大文件有序内存排序（远高于内存，分隔，分别排序，缓冲区）

对于远高于内存的文件排序。

外归并排序：

- 对文件分割，然后分别排序。
- 排好序的文件依次读取一个缓冲区的大小，然后进行排序，输出到输出缓冲区，然后保存到结果文件。

如果是数字，可以用位图排序，但是要求比较苛刻：

- 数字不重复
- 知道最大值
- 相对密集，因为没出现的数字也会占用空间

比较适合电话号之类的。

[【算法】对一个20GB大的文件排序](https://blog.csdn.net/michellechouu/article/details/47002393)

外归并排序（External merge sort），它读入一些能放在内存内的数据量，在内存中排序后输出为一个顺串（即是内部数据有序的临时文件），处理完所有的数据后再进行归并。比如，要对900MB的数据进行排序，但机器上只有100 MB的可用内存时，外归并排序按如下方法操作：

读入100 MB的数据至内存中，用某种常规方式（如快速排序、堆排序、归并排序等方法）在内存中完成排序。
将排序完成的数据写入磁盘。
重复步骤1和2直到所有的数据都存入了不同的100 MB的块（临时文件）中。在这个例子中，有900 MB数据，单个临时文件大小为100 MB，所以会产生9个临时文件。
读入每个临时文件（顺串）的前10 MB（ = 100 MB / (9块 + 1)）的数据放入内存中的输入缓冲区，最后的10 MB作为输出缓冲区。（实践中，将输入缓冲适当调小，而适当增大输出缓冲区能获得更好的效果。）
执行九路归并算法，将结果输出到输出缓冲区。一旦输出缓冲区满，将缓冲区中的数据写出至目标文件，清空缓冲区。一旦9个输入缓冲区中的一个变空，就从这个缓冲区关联的文件，读入下一个10M数据，除非这个文件已读完。这是外归并排序能在主存外完成排序的关键步骤 -- 因为归并算法(merge algorithm)对每一个大块只是顺序地做一轮访问(进行归并)，每个大块不用完全载入主存。

### 子业务场景

#### 外卖送单，保证只有一人接到（redis的lpush、rpop）

#### 加权推荐商家置顶，第二天更新（堆排序，第二天更新前redis准备好数据同步到db）

#### 微信抢红包（悲观锁、乐观锁、存储过程在mysql中）

#### 多任务分配有限人处理及优化（对象池、任务入N个队列，人去对应的队列取任务）

#### 保证发送消息的有序性（消息加header、识别header的syn）

#### 文件快速下发到服务（边下发边复制）

#### 多台机器存储大量日志，一台电脑选出热度最高的十个关键词（分bucket、分治法与多路归并）

#### 分布式集群如何保证线程安全（分布式锁，让分布式多线程对一个共享资源一次性只能有一个线程获取到锁里的资源，redis、zk居多）

## 实现方式与概念

### 负载均衡原理是什么?

负载均衡Load Balance）是高可用网络基础架构的关键组件，通常用于将工作负载分布到多个服务器来提高网站、应用、数据库或其他服务的性能和可靠性。负载均衡，其核心就是网络流量分发，分很多维度。

负载均衡是建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。

用户访问负载均衡器，再由负载均衡器将请求转发给后端服务器。在这种情况下，单点故障现在转移到负载均衡器上了。 这里又可以通过引入第二个负载均衡器来缓解。

负载均衡器如何选择要转发的后端服务器？

负载均衡器一般根据两个因素来决定要将请求转发到哪个服务器。首先，确保所选择的服务器能够对请求做出响应，然后根据预先配置的规则从健康服务器池（healthy pool）中进行选择。

因为，负载均衡器应当只选择能正常做出响应的后端服务器，因此就需要有一种判断后端服务器是否健康的方法。为了监视后台服务器的运行状况，运行状态检查服务会定期尝试使用转发规则定义的协议和端口去连接后端服务器。 如果，服务器无法通过健康检查，就会从池中剔除，保证流量不会被转发到该服务器，直到其再次通过健康检查为止。

负载均衡算法?

负载均衡算法决定了后端的哪些健康服务器会被选中。 其中常用的算法包括：

- Round Robin（轮询）：为第一个请求选择列表中的第一个服务器，然后按顺序向下移动列表直到结尾，然后循环。
- Least Connections（最小连接）：优先选择连接数最少的服务器，在普遍会话较长的情况下推荐使用。
- Source：根据请求源的 IP 的散列（hash）来选择要转发的服务器。这种方式可以一定程度上保证特定用户能连接到相同的服务器。
- 如果你的应用需要处理状态而要求用户能连接到和之前相同的服务器。可以通过 Source 算法基于客户端的 IP 信息创建关联，或者使用粘性会话（sticky sessions）。

除此之外，想要解决负载均衡器的单点故障问题，可以将第二个负载均衡器连接到第一个上，从而形成一个集群。

### 滑动窗口的概念以及应用（流量控制技术，改善吞吐量，用在数据链路层、传输层）

### 怎么做弹性扩缩容，原理是什么

### 说一下中间件原理，设计

### 设计一个web框架，你要怎么设计，说一下步骤

###### 怎么搞一个并发服务程序

### 怎么做一个自动化配置平台系统

### 各个系统出问题怎么监控报警

### 怎么设计orm，让你写,你会怎么写

### 电商交易订单系统

[数据冷热分离技术](https://cloud.tencent.com/developer/article/1798044)

在系统选型上，对于热数据系统，需要重点考虑读写的性能问题，诸如MySQL、Elasticsearch等会成为首选；而对于冷数据系统，则需要重点关注低成本存储问题，通常会选择存储在HDFS或云对象存储（比如AWS S3）中，再选择一个相应的查询系统。冷热数据是按照时间推移来区分的，因此必然要敲定一个时间分割线，即多久以内的数据为热数据，这个值通常会结合业务与历史访问情况来综合考量。对于超过时间线的数据，会被迁移到冷数据中，迁移过程需要确保两点：不能对热数据系统产生性能影响、不能影响数据查询。数据分离后，不可避免的会出现某个查询在时间上跨到两个系统里面，需要进行查询结果的合并，对于统计类查询就可能会出现一定的误差，需要在业务层面有所妥协。

业务背景是，用户在系统下单后会生成相应的交易订单信息，每天会产生大量的订单数据。这些数据需要永久保存，随时面对用户的低延迟查询，通常近3个月的订单是用户查询的主要对象。

在该系统中，热数据毫无疑问会采用MySQL(InnoDB)来实现，满足事务操作和高效查询的需求。当然，在查询系统前面还会有一层缓存，这里略过。冷数据以宽表的形式存储到HBase中，并采用Elasticsearch来提供相关的索引查询，配合HBase的数据查询。热数据在MySQL中保留90天，之后迁移到HBase中作为冷数据永久保存。

对于一个交易请求，会先在MySQL的订单表中创建订单记录，这些操作会通过BinLog同步到Kafka中，由Spark Streaming程序从Kafka中将相关订单信息变动提取出来，做相应的关联处理后写入到HBase中，同时更新Elasticsearch中的索引信息。每天定期将冷热分割线往前推移，并删除热数据中对应时间的订单表。

### 验证码

## 思路

从以下几个方面准备：

- 先了解常用算法，针对解决各种问题能用哪些算法，比如大文件排序用外排序，大量数据中的命中判断用位图/布隆过滤器等等。
- 注意扩展性、多考虑极端情况，多问自己几个为什么。比如说起单机的限流算法想想分布式的怎么做。
- 实在不知道怎么弄的叙述自己的思考过程，着重展示自己考虑周全、思维缜密。
